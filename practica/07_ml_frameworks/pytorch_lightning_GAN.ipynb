{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir=\"./data\", batch_size=128, num_workers=int(os.cpu_count() / 2)):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1,), (0.3,))\n",
    "        ])\n",
    "        \n",
    "\n",
    "        self.dl_dict = {'batch_size': self.batch_size, 'num_workers': self.num_workers}\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets.MNIST(self.data_dir, train=True, download=True)\n",
    "        datasets.MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Validation data not strictly necessary for GAN but added for completeness\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = datasets.MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = datasets.MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "    \n",
    "    ## For dataloaders, usually just wrap dataset defined in setup\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, **self.dl_dict)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, **self.dl_dict)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, **self.dl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Simple CNN\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # Flatten the tensor so it can be fed into the FC layers\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(latent_dim, 7*7*64)\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2)\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2)\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(self, x):\n",
    "        # Pass latent space input into linear layer and reshape\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)\n",
    "\n",
    "        \n",
    "        # Transposed convolution to 16x16 (64 feature maps)\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Transposed convolution to 34x34 (16 feature maps)\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Convolution to 28x28 (1 feature map)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    ## Initialize. Define latent dim, learning rate, and Adam betas \n",
    "    def __init__(self, latent_dim=100, lr=0.0002, \n",
    "\n",
    "                 b1=0.5, b2=0.999, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        real_imgs, _ = batch\n",
    "\n",
    "        # sample noise\n",
    "        z = torch.randn(real_imgs.shape[0], self.hparams.latent_dim)\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            self.generated_imgs = self(z)\n",
    "            predictions = self.discriminator(self.generated_imgs)\n",
    "            g_loss = self.adversarial_loss(predictions, torch.ones(real_imgs.size(0), 1))\n",
    "            \n",
    "\n",
    "            # log sampled images\n",
    "            sample_imgs = self.generated_imgs[:6]\n",
    "            grid = torchvision.utils.make_grid(sample_imgs)\n",
    "            self.logger.experiment.add_image(\"generated_images\", grid, 0)\n",
    "\n",
    "\n",
    "            tqdm_dict = {\"g_loss\": g_loss}\n",
    "            output = OrderedDict({\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            real_preds = self.discriminator(real_imgs)\n",
    "            real_loss = self.adversarial_loss(real_preds, torch.ones(real_imgs.size(0), 1))\n",
    "\n",
    "            fake_preds = self.discriminator(self(z).detach())\n",
    "            fake_loss = self.adversarial_loss(fake_preds, torch.zeros(real_imgs.size(0), 1)) \n",
    "\n",
    "\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {\"d_loss\": d_loss}\n",
    "            output = OrderedDict({\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [opt_g, opt_d], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(self):\n",
    "        # log sampled images\n",
    "        sample_imgs = self(self.validation_z)\n",
    "        grid = torchvision.utils.make_grid(sample_imgs)\n",
    "        self.logger.experiment.add_image(\"generated_images\", grid, self.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule()\n",
    "model = GAN()\n",
    "trainer.fit(model, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
